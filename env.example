# Copy this file to .env and update with your values
## cp env.example .env

# =============================================================================
# DATABASE CONFIGURATION - REQUIRED
# =============================================================================
# External PostgreSQL database connection string (primary application DB)
# Format: postgresql+psycopg2://username:password@host:port/database?sslmode=require
# See DATABASE_SETUP.md for detailed instructions and examples

DATABASE_URL=postgresql+psycopg2://user:password@host:port/dbname?sslmode=require

# Dedicated Neon database for FinAgent metadata, imported datasets, normalized market data,
# and LLM prompt/response archiving. Use the same format as DATABASE_URL.
# If omitted, the system falls back to DATABASE_URL.
NEON_DATABASE=postgresql+psycopg2://user:password@ep-example.neon.tech/finagent_meta?sslmode=require

# Example for Neon:
# DATABASE_URL=postgresql+psycopg2://user:pass@ep-example.us-east-1.aws.neon.tech/dbname?sslmode=require

# Example for local PostgreSQL (running outside Docker):
# DATABASE_URL=postgresql+psycopg2://postgres:postgres@host.docker.internal:5432/ibkr_trading

# =============================================================================
# INTERACTIVE BROKERS CONFIGURATION
# =============================================================================
IBKR_ACCOUNT_ID=DU1234567

# =============================================================================
# MINIO CONFIGURATION (Object Storage for Charts)
# =============================================================================
# Defaults work for Docker setup, change if needed
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin

# =============================================================================
# OPENAI / LLM CONFIGURATION
# =============================================================================
# Your OpenAI API key or compatible service API key
OPENAI_API_KEY=your_openai_api_key_here

# OpenAI API Base URL - supports OpenAI-compatible APIs
# The application will automatically append /chat/completions, /embeddings, etc.
# Examples:
#   - OpenAI Official: https://api.openai.com/v1
#   - TuringAI: https://turingai.plus/v1
#   - Azure OpenAI: https://your-resource.openai.azure.com/openai/deployments/your-deployment
#   - Local LLM: http://localhost:11434/v1
OPENAI_API_BASE=https://api.openai.com/v1

# Model configuration
OPENAI_MODEL=gpt-4-turbo-preview
LLM_VISION_MODEL=gpt-4-vision-preview
LLM_VISION_PROVIDER=openai

# =============================================================================
# FINAGENT CONFIGURATION
# =============================================================================
FINAGENT_ENABLED=false
FINAGENT_MODEL_PATH=reference/finagent_runtime/checkpoints/base
FINAGENT_REFLECTION_ROUNDS=2
FINAGENT_TOOLKIT=technical_indicators,news_memory,rl_baseline

# Optional FinAgent vector memory (Weaviate Cloud)
# Example snippet (matches build scripts):
#   import os
#   import weaviate
#   from weaviate.classes.init import Auth
#   client = weaviate.connect_to_weaviate_cloud(
#       cluster_url=os.environ["WEAVIATE_URL"],
#       auth_credentials=Auth.api_key(os.environ["WEAVIATE_API_KEY"]),
#   )
WEAVIATE_URL=https://your-cluster.weaviate.network
WEAVIATE_API_KEY=your_weaviate_key

# =============================================================================
# MARKET DATA CACHE & DEBUG MODE
# =============================================================================
# Enable debug mode to use cached data instead of live IBKR API calls
DEBUG_MODE=false

# Enable market data caching (recommended)
CACHE_ENABLED=true

# Symbols to cache by default (comma-separated)
CACHE_SYMBOLS=NVDA,TSLA

# Default exchange for cached symbols
CACHE_EXCHANGE=NASDAQ

# Cache time-to-live in hours
CACHE_TTL_HOURS=24

# =============================================================================
# AIRFLOW CONFIGURATION
# =============================================================================
# Airflow uses the same DATABASE_URL as the backend (no separate database needed)
# Airflow creates its own tables with 'alembic_version' and other Airflow-specific prefixes

# Airflow user ID (use $(id -u) on Linux/Mac to get your user ID)
AIRFLOW_UID=50000

# Airflow web UI credentials
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=airflow

# Airflow project directory (default is current directory)
AIRFLOW_PROJ_DIR=.

# =============================================================================
# MLFLOW CONFIGURATION
# =============================================================================
# MLflow uses the same DATABASE_URL as the backend (no separate database needed)
# MLflow creates its own tables with 'mlflow_' prefixes

# MinIO credentials for MLflow artifact storage (should match MINIO_* above)
# These are automatically set from MINIO_ACCESS_KEY and MINIO_SECRET_KEY
# AWS_ACCESS_KEY_ID=minioadmin
# AWS_SECRET_ACCESS_KEY=minioadmin

# =============================================================================
# OPTIONAL: LEGACY POSTGRESQL VARIABLES
# =============================================================================
# These are no longer used since PostgreSQL is external
# Kept for reference only
# POSTGRES_USER=postgres
# POSTGRES_PASSWORD=postgres
# POSTGRES_DB=ibkr_trading
